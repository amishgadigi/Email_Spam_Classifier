{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam Filter #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a project to classify emails as spam or not. This is basically a Spam-filter. The dataset used for this project can be found here: http://spamassassin.apache.org/old/publiccorpus/. SVM Classifier will be used for this project. The following major packages will be used for this project:\n",
    "\n",
    "- tarfile - For extracting tar files\n",
    "- os - For accessing folders and files on local computer\n",
    "- nltk - For natural language proecessing\n",
    "- re - For regular expressions\n",
    "- BeautifulSoup - For handling HTML tags\n",
    "- Numpy - For working with arrays\n",
    "- scikit-learn - For machine learning algorithms\n",
    "\n",
    "Packages will be imported as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting files\n",
    "Please note that all dataset files are assumed to be downloaded for this project. The dataset files are downloaded from  http://spamassassin.apache.org/old/publiccorpus/ and saved in the same folder as the folder of this Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not already downloaded, punkt and stopwords need to be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filenames of the tar files are manually stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_filenames = ['20021010_easy_ham.tar.bz2', '20021010_hard_ham.tar.bz2', '20021010_spam.tar.bz2', '20030228_easy_ham.tar.bz2', '20030228_easy_ham_2.tar.bz2', '20030228_hard_ham.tar.bz2', '20030228_spam.tar.bz2','20030228_spam_2.tar.bz2','20050311_spam_2.tar.bz2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tar files are extracrted and stored in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tar_filenames:\n",
    "    tar_file = tarfile.open(filename,'r:bz2')\n",
    "    tar_file.extractall(path=(\".\\\\\" + filename[0:-8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the path for the emails. The path has a pattern based on the file name of the tar files. This can be tested by deleting the first unnencessary file in the third tar file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = tar_filenames[2]\n",
    "path = '.\\\\' + filename[0:-8]+'\\\\' + filename[9:-8]+'\\\\'\n",
    "emails = os.listdir(path)\n",
    "os.remove(path+emails[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening emails and processing them.\n",
    "\n",
    "The data is already divided into spam and not spam. So for processing the datasets, before they are combined for training, the data will be stored in different variables in every stage.\n",
    "Filenames are divided bbetween spam files and not spam files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_filenames = list(filter(lambda x: (re.search('spam', x)), tar_filenames))\n",
    "valid_filenames = list(filter(lambda x: (x not in spam_filenames), tar_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'folder_open' accepts an email and returns tokensized words. There are some files which do not use standard encoding. This function skips those files whic cannot be read.\n",
    "\n",
    "The function 'email_tokens' accepts the contents of the email and turns them into word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_open(filename):\n",
    "    path = '.\\\\' + filename[0:-8]+'\\\\' + filename[9:-8]+'\\\\'\n",
    "    emails = os.listdir(path)\n",
    "    tokens_emails = []\n",
    "    for email in emails:\n",
    "        f = open(path+email)\n",
    "        try:\n",
    "            emailcontents = f.read()\n",
    "            etokens = email_tokens(emailcontents)\n",
    "            tokens_emails.append(etokens)\n",
    "        except UnicodeDecodeError:\n",
    "            result = chardet.detect(open(path+email,'rb').read())\n",
    "            print(path+email)\n",
    "            print(result['encoding'])      \n",
    "            print('\\n')\n",
    "        except AttributeError as a:\n",
    "            print(path+email)\n",
    "            print(a)\n",
    "        f.close()\n",
    "    return tokens_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_tokens(emailcontents):\n",
    "    #Remove Headers\n",
    "    emailcontents = emailcontents[re.search('\\n\\n',emailcontents).span(0)[1]:]\n",
    "    \n",
    "    #Stripping HTML tags\n",
    "    emailcontents = bs(emailcontents).get_text()\n",
    "    \n",
    "    #Handling HTTP links\n",
    "    emailcontents = re.sub(r'(http|https)://[^\\s]*','httpaddr',emailcontents)\n",
    "    emailcontents = re.sub(r'www.[^\\s]*','httpaddr',emailcontents)\n",
    "    \n",
    "    #Handling Email addresses\n",
    "    emailcontents = re.sub(r'[^\\s]+@[^\\s]+','emailpaddr',emailcontents)\n",
    "    \n",
    "    #Convert everything to lowercase\n",
    "    emailcontents = emailcontents.lower()\n",
    "    \n",
    "    #Handling Numbers\n",
    "    emailcontents = re.sub(r'[0-9]+',' number ',emailcontents)\n",
    "    \n",
    "    #Handling $ signs\n",
    "    emailcontents = emailcontents.replace('$',' dollar ')\n",
    "    \n",
    "    #Create tokens\n",
    "    etokens = nltk.word_tokenize(emailcontents)\n",
    "    \n",
    "    #Removing non-alphanumeric characters\n",
    "    etokens = [re.sub('\\W|_','',etoken) for etoken in etokens]\n",
    "    \n",
    "    #Removing empty tokens\n",
    "    etokens = list(filter(None, etokens))\n",
    "    \n",
    "    #Removing Stop Words\n",
    "    etokens = list(filter(lambda x: (x not in stop_words), etokens))\n",
    "    \n",
    "    #Stemming\n",
    "    porter = nltk.PorterStemmer()\n",
    "    etokens = [porter.stem(t) for t in etokens]\n",
    "    \n",
    "    #Removing any words less than 3 letters\n",
    "    etokens = list(filter(lambda x: (len(x)>=3), etokens))\n",
    "    \n",
    "    return etokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word tokens are created separately for spam files and not spam files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamtokens = []\n",
    "validtokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\20021010_spam\\spam\\0123.68e87f8b736959b1ab5c4b5f2ce7484a\n",
      "Windows-1254\n",
      "\n",
      "\n",
      ".\\20021010_spam\\spam\\0273.51c482172b47ce926021aa7cc2552549\n",
      "SHIFT_JIS\n",
      "\n",
      "\n",
      ".\\20021010_spam\\spam\\0330.a4df526233e524104c3b3554dd8ab5a8\n",
      "SHIFT_JIS\n",
      "\n",
      "\n",
      ".\\20021010_spam\\spam\\0334.3e4946e69031f3860ac6de3d3f27aadd\n",
      "SHIFT_JIS\n",
      "\n",
      "\n",
      ".\\20021010_spam\\spam\\0335.9822e1787fca0741a8501bdef7e8bc79\n",
      "SHIFT_JIS\n",
      "\n",
      "\n",
      ".\\20030228_spam\\spam\\00116.29e39a0064e2714681726ac28ff3fdef\n",
      "Windows-1254\n",
      "\n",
      "\n",
      ".\\20030228_spam\\spam\\00263.13fc73e09ae15e0023bdb13d0a010f2d\n",
      "SHIFT_JIS\n",
      "\n",
      "\n",
      ".\\20030228_spam\\spam\\00320.20dcbb5b047b8e2f212ee78267ee27ad\n",
      "SHIFT_JIS\n",
      "\n",
      "\n",
      ".\\20030228_spam\\spam\\00323.9e36bf05304c99f2133a4c03c49533a9\n",
      "SHIFT_JIS\n",
      "\n",
      "\n",
      ".\\20030228_spam\\spam\\00324.6f320a8c6b5f8e4bc47d475b3d4e86ef\n",
      "SHIFT_JIS\n",
      "\n",
      "\n",
      ".\\20030228_spam\\spam\\00500.85b72f09f6778a085dc8b6821965a76f\n",
      "GB2312\n",
      "\n",
      "\n",
      ".\\20030228_spam\\spam\\cmds\n",
      "'NoneType' object has no attribute 'span'\n",
      ".\\20030228_spam_2\\spam_2\\01065.9ecef01b01ca912fa35453196b4dae4c\n",
      "Windows-1254\n",
      "\n",
      "\n",
      ".\\20030228_spam_2\\spam_2\\01227.04a4f94c7a73b29cb56bf38c7d526116\n",
      "Windows-1254\n",
      "\n",
      "\n",
      ".\\20030228_spam_2\\spam_2\\01376.73e738e4cd8121ce3dfb42d190b193c9\n",
      "Windows-1254\n",
      "\n",
      "\n",
      ".\\20030228_spam_2\\spam_2\\cmds\n",
      "'NoneType' object has no attribute 'span'\n",
      ".\\20050311_spam_2\\spam_2\\01065.9ecef01b01ca912fa35453196b4dae4c\n",
      "Windows-1254\n",
      "\n",
      "\n",
      ".\\20050311_spam_2\\spam_2\\01227.04a4f94c7a73b29cb56bf38c7d526116\n",
      "Windows-1254\n",
      "\n",
      "\n",
      ".\\20050311_spam_2\\spam_2\\01376.73e738e4cd8121ce3dfb42d190b193c9\n",
      "Windows-1254\n",
      "\n",
      "\n",
      ".\\20050311_spam_2\\spam_2\\cmds\n",
      "'NoneType' object has no attribute 'span'\n"
     ]
    }
   ],
   "source": [
    "for spam_filename in spam_filenames:\n",
    "    spamtokens.append(folder_open(spam_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amish\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:336: UserWarning: \"http://www.post-gazette.com/columnists/20020905brian5.asp\n",
      "\n",
      "\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\20030228_easy_ham\\easy_ham\\cmds\n",
      "'NoneType' object has no attribute 'span'\n",
      ".\\20030228_easy_ham_2\\easy_ham_2\\cmds\n",
      "'NoneType' object has no attribute 'span'\n",
      ".\\20030228_hard_ham\\hard_ham\\cmds\n",
      "'NoneType' object has no attribute 'span'\n"
     ]
    }
   ],
   "source": [
    "for valid_filename in valid_filenames:\n",
    "    validtokens.append(folder_open(valid_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validtokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on Tokens\n",
    "\n",
    "Currently the emails are arranged by the tar files they are extracted from. In the next few steps the emails (which are only token words now) will be arranged in a single file.\n",
    "\n",
    "A copy of all tokens will also be gathered together to create a vocabulary list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3776"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allspamtokens = [spamtokens2 for spamtokens1 in spamtokens for spamtokens2 in spamtokens1]\n",
    "len(allspamtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyspamtokens = [allspamtokens2 for allspamtokens1 in allspamtokens for allspamtokens2 in allspamtokens1]\n",
    "len(onlyspamtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6951"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvalidtokens = [validtokens2 for validtokens1 in validtokens for validtokens2 in validtokens1]\n",
    "len(allvalidtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1230575"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyvalidtokens =  [validtokens2 for validtokens1 in allvalidtokens for validtokens2 in validtokens1]\n",
    "len(onlyvalidtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlytokens = onlyspamtokens + onlyvalidtokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabWords = nltk.Text(onlytokens).vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_onlytokens = sorted(vocabWords, key = vocabWords.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabWords[sorted_onlytokens[12959]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only those words are considered which have at least 10 occurrences in the emails. Based on that criteria we are considering the 12960 most used words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = sorted_onlytokens[0:12960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epicentr'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list[12959]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Indices are vectors of the emails based on the position of tokens in the vocabulary list. So each email will have the same length of word indices as they all represent whether a word is in the vocabulary list. For words not in vocabulary list, -1 value is assigned.  So an extra column is provided in word indices to accomodate them. So words not in the list will assigned to -1 location in the array which is the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordindicesspam = allspamtokens\n",
    "wordindicesvalid = allvalidtokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordindicesspam = [[vocab_list.index(x) if x in vocab_list else -1 for x in indspamtokens] for indspamtokens in allspamtokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3776"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordindicesspam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordindicesvalid = [[vocab_list.index(x) if x in vocab_list else -1 for x in indvalidtokens] for indvalidtokens in allvalidtokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6951"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordindicesvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices will be one-hot-encoded and stored in numpy arrays. The last column is eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xspam = np.zeros((len(wordindicesspam), len(vocab_list)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvalid = np.zeros((len(wordindicesvalid), len(vocab_list)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wordindicesspam)):\n",
    "    Xspam[i][wordindicesspam[i][:]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wordindicesvalid)):\n",
    "    Xvalid[i][wordindicesvalid[i][:]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xspam = Xspam[:,0:len(vocab_list)]\n",
    "Xvalid = Xvalid[:,0:len(vocab_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3776, 12960)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xspam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Machine Learning\n",
    "\n",
    "Combining the spam and valid emails together into the X variable. A column is provided at the end to store values of whether if the emails are spam or not. If the email is spam then the value of 1 is stored and if its not 0 is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(wordindicesspam) + len(wordindicesvalid), len(vocab_list)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:len(wordindicesspam),0:len(vocab_list)] = Xspam\n",
    "X[len(wordindicesspam):(len(wordindicesspam) + len(wordindicesvalid)),0:len(vocab_list)]\n",
    "X[0:len(wordindicesspam), len(vocab_list)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10727, 12961)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata = X[:,0: len(vocab_list)]\n",
    "ydata = X[:, len(vocab_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing the actual analysis, a test analysis will help to let us know what to expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(gamma=0.001, C=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98556125, 0.98927739, 0.98787879, 0.98741259, 0.98787879])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, Xdata, ydata, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 98% accuracy is good, let us see if we can improve the accuracy.\n",
    "\n",
    "Splitting the datasets into test and train sets. Also using kfolds cross validation technique to compare results. Also comparing against different values of hyper-paramenter C. The different values of C used is 0.0001, 0.001, 0.1, 1, 10 and 100. We will be using Support Vector Machine Classifierm for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( Xdata, ydata, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=4)\n",
    "kf.get_n_splits(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C is 0.0001\n",
      "0.6500465983224604\n",
      "0.6477166821994408\n",
      "\n",
      "\n",
      "0.6298368298368299\n",
      "0.6477166821994408\n",
      "\n",
      "\n",
      "0.6564102564102564\n",
      "0.6477166821994408\n",
      "\n",
      "\n",
      "0.6559440559440559\n",
      "0.6477166821994408\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "C is 0.001\n",
      "0.6500465983224604\n",
      "0.6477166821994408\n",
      "\n",
      "\n",
      "0.6298368298368299\n",
      "0.6477166821994408\n",
      "\n",
      "\n",
      "0.6564102564102564\n",
      "0.6477166821994408\n",
      "\n",
      "\n",
      "0.6559440559440559\n",
      "0.6477166821994408\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "C is 0.1\n",
      "0.9482758620689655\n",
      "0.9538676607642125\n",
      "\n",
      "\n",
      "0.9496503496503497\n",
      "0.9538676607642125\n",
      "\n",
      "\n",
      "0.9543123543123543\n",
      "0.9534016775396086\n",
      "\n",
      "\n",
      "0.9501165501165502\n",
      "0.9538676607642125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "C is 1\n",
      "0.9874184529356943\n",
      "0.9878844361602982\n",
      "\n",
      "\n",
      "0.985081585081585\n",
      "0.9874184529356943\n",
      "\n",
      "\n",
      "0.9864801864801864\n",
      "0.9883504193849021\n",
      "\n",
      "\n",
      "0.986013986013986\n",
      "0.9878844361602982\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "C is 10\n",
      "0.9958061509785647\n",
      "0.9962721342031687\n",
      "\n",
      "\n",
      "0.9958041958041958\n",
      "0.9953401677539608\n",
      "\n",
      "\n",
      "0.9958041958041958\n",
      "0.9953401677539608\n",
      "\n",
      "\n",
      "0.9944055944055944\n",
      "0.9958061509785647\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "C is 100\n",
      "0.9976700838769804\n",
      "0.9981360671015843\n",
      "\n",
      "\n",
      "0.9972027972027973\n",
      "0.9986020503261882\n",
      "\n",
      "\n",
      "0.9981351981351981\n",
      "0.9990680335507922\n",
      "\n",
      "\n",
      "0.9972027972027973\n",
      "0.9981360671015843\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in [0.0001, 0.001, 0.1, 1, 10, 100]:\n",
    "    print('C is '+str(c))\n",
    "    for train_index, cv_index in kf.split(X_train,y_train):        \n",
    "        cvmodel = svm.SVC(gamma=0.001, C=c)\n",
    "        cvmodel.fit(X_train[train_index], y_train[train_index])\n",
    "        cv_score = cvmodel.score(X_train[cv_index],y_train[cv_index])\n",
    "        test_score = cvmodel.score(X_test, y_test)\n",
    "        print(cv_score)\n",
    "        print(test_score)\n",
    "        print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, we can deduce that higher C gives better score. So let us increase C also check against sigmoid kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'svc__C': [100, 500], 'svc__kernel': ['rbf', 'sigmoid']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "pipe = Pipeline(steps=[('svc',model)])\n",
    "grid = dict(svc__C=[100, 500], svc__kernel=['rbf','sigmoid'])\n",
    "estimator = GridSearchCV(pipe, grid, n_jobs=-1)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9962708309054888"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 500, 'svc__kernel': 'rbf'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9976692693159306"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So RBF kernel gives the best results and also higher C is still giving better results but the score improvement is marginal. So let us one last time for higher values of C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'svc__C': [500, 1000, 2000]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "pipe = Pipeline(steps=[('svc',model)])\n",
    "grid = dict(svc__C=[500, 1000, 2000])\n",
    "estimator = GridSearchCV(pipe, grid, n_jobs=-1)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975527327817271"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 2000}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983684885211513"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So finally we get pretty good score for both cross validated train set and the test set. So we can use this as an email spam classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
